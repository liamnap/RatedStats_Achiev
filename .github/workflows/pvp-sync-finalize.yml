name: Finalize PvP Sync
run-name: Finalize PvP Sync for ${{ inputs.region }}

# Trigger whenever the "PvP Sync Batch" workflow finishes on dev
on:
  workflow_run:
    workflows: ["PvP Sync Batch"]
    types: [completed]
  workflow_dispatch:
    inputs:
      region:
        description: "Region to finalize"
        required: true
        type: choice
        options: [kr, tw, eu, us]
      sha:
        description: "Head SHA of the batch runs to finalize"
        required: true
        type: string
      branch:
        description: "Branch the batch runs executed on"
        required: true
        type: string

permissions:
  contents: write
  actions: read

jobs:
  guard:
    # fire on: (a) workflow_dispatch, or (b) any "PvP Sync Batch" completion (all regions)
    if: >
      (github.event_name == 'workflow_dispatch') ||
      (github.event.workflow_run.name == 'PvP Sync Batch')
    name: Check if this was the last batch
    runs-on: ubuntu-latest
    concurrency:
      # one finalize per region+sha regardless of trigger type
      group: finalize-${{ needs.guard.outputs.region }}-${{ github.event.workflow_run.head_sha || inputs.sha || github.sha }}
      cancel-in-progress: false
    outputs:
      is_final: ${{ steps.parse.outputs.is_final }}
      region:   ${{ steps.parse.outputs.region }}
      total:    ${{ steps.parse.outputs.total }}
    steps:
      - name: Determine region + whether this is the final batch
        id: parse
        shell: bash
        run: |
          set -euo pipefail
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "region=${{ inputs.region }}" >>"$GITHUB_OUTPUT"
            echo "is_final=true" >>"$GITHUB_OUTPUT"
            echo "üü¢ Finalize via dispatch: region='${{ inputs.region }}'"
            exit 0
          fi

          TITLE="${{ github.event.workflow_run.display_title }}"
          echo "Run title: $TITLE"
          # Expect: "PvP Sync Batch 3 / 10 for kr"
          if [[ "$TITLE" =~ ^PvP[[:space:]]Sync[[:space:]]Batch[[:space:]]([0-9]+)[[:space:]]*/[[:space:]]*([0-9]+)[[:space:]]for[[:space:]]([a-z]{2})$ ]]; then
            CUR="${BASH_REMATCH[1]}"; TOT="${BASH_REMATCH[2]}"; REGION="${BASH_REMATCH[3]}"
            echo "region=$REGION" >>"$GITHUB_OUTPUT"
            echo "total=$TOT"     >>"$GITHUB_OUTPUT"
            if [[ "$CUR" == "$TOT" ]]; then
              echo "is_final=true"  >>"$GITHUB_OUTPUT"
              echo "‚úÖ Detected final batch ($CUR/$TOT) for $REGION"
            else
              echo "is_final=false" >>"$GITHUB_OUTPUT"
              echo "‚è≠ Not final batch ($CUR/$TOT) for $REGION ‚Üí skipping finalize."
            fi
          else
            echo "is_final=false" >>"$GITHUB_OUTPUT"
            echo "‚ö†Ô∏è Couldn't parse batch info; aborting finalize."
          fi

  finalize:
    if: >
      needs.guard.outputs.is_final == 'true' &&
      (
        (github.event_name == 'workflow_run'     && github.event.workflow_run.conclusion == 'success')
        ||
        (github.event_name == 'workflow_dispatch')
      )
    needs: guard
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 1
          ref: ${{ github.event.workflow_run.head_branch || inputs.branch }}
          lfs: false   # don't fail if LFS objects were cleaned up

      - name: (Optional) Hydrate LFS if available, but never fail
        env:
          # Don‚Äôt auto-download LFS during checkout (keeps pointers only)
          GIT_LFS_SKIP_SMUDGE: "1"
        run: |
          set +e
          git lfs install --local
          git lfs fetch
          git lfs checkout
          # If LFS server has pruned objects you‚Äôll see 410/404; we ignore it.
          echo "LFS hydration attempted (continuing even if it failed)."

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Enable Git LFS
        run: |
          git lfs install --local
          git lfs env

      - name: Install runtime deps
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp requests psutil

      - name: Check disk usage
        run: df -h

      - name: Wait for ALL region batch runs to complete
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          wf="PvP Sync Batch"
          region="${{ needs.guard.outputs.region }}"
          sha="${{ github.event.workflow_run.head_sha }}"
          branch="${{ github.event.workflow_run.head_branch }}"
          # Fallbacks for workflow_dispatch
          if [[ -z "$sha" ]]; then sha="${{ inputs.sha }}"; fi
          if [[ -z "$branch" ]]; then branch="${{ inputs.branch }}"; fi
          echo "Waiting for all '$wf' runs for region=$region, sha=$sha..."
          while true; do
            # find any runs still pending/running for this sha+region
            rem=$(gh run list \
                  -w "$wf" -b "$branch" -L 500 \
                  --json status,displayTitle,headSha \
                  --jq "[ .[]
                          | select(.headSha==\"$sha\")
                          | select(.displayTitle|endswith(\" for $region\"))
                          | select(.status!=\"completed\") ] | length")
            if (( rem == 0 )); then
              echo "‚úÖ All $wf runs for $region/$sha are done."
              break
            fi
            echo "‚è≥ $rem runs still in progress‚Ä¶"
            sleep 10
          done

      - name: Download every batch‚Äôs DB shard
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          wf="PvP Sync Batch"
          region="${{ needs.guard.outputs.region }}"
          sha="${{ github.event.workflow_run.head_sha }}"
          branch="${{ github.event.workflow_run.head_branch }}"
          expected="${{ needs.guard.outputs.total }}"
          # Fallbacks for workflow_dispatch
          if [[ -z "$sha" ]]; then sha="${{ inputs.sha }}"; fi
          if [[ -z "$branch" ]]; then branch="${{ inputs.branch }}"; fi
          mkdir -p partial_outputs
          # grab the list of run IDs for this sha+region
          # First pass: only runs from THIS commit (sha)
          ids=$(gh run list \
                  -w "$wf" -b "$branch" -c "$sha" -s completed -L 500 \
                  --json databaseId,displayTitle,conclusion \
                  --jq "[ .[] | select(.conclusion==\"success\") | select(.displayTitle|endswith(\" for $region\")) | .databaseId ] | unique | .[]")

          # download only the DB artifacts for this region, into a temp dir
          rm -rf _dl && mkdir -p _dl
          for id in $ids; do
            echo "Downloading DB artifacts from run $id‚Ä¶"
            gh run download "$id" \
              --pattern "pvp-db-${region}-batch-*" \
              -D _dl || true
          done
          # flatten sqlite shards into ./partial_outputs (handle any nested layout)
          shopt -s globstar nullglob
          found_any=0
          for f in _dl/**/achdb_${region}_b*.sqlite; do
            echo "Copying shard: $f"
            cp -f "$f" partial_outputs/
            found_any=1
          done
          if [[ $found_any -eq 0 ]]; then
            echo "‚ùå No achdb_${region}_b*.sqlite found under _dl/"
            echo "Directory tree for debugging:"
            ls -laR _dl || true
          fi
          echo "Found shards:"
          ls -1 partial_outputs || true
          # show row counts BEFORE any cleanup
          cnt=$(ls -1 partial_outputs/achdb_${region}_b*.sqlite 2>/dev/null | wc -l || true)
          if (( cnt == 0 )); then
            echo "‚ùå No shards found ‚Äî skipping region_${region}.lua write!"
            touch region_${region}.lua
          else
            echo "‚úÖ Found $cnt shard(s), continuing to finalize region_${region}.lua"
            for dbf in partial_outputs/achdb_${region}_b*.sqlite; do
              echo -n "rows in $(basename "$dbf"): "
              sqlite3 "$dbf" "SELECT COUNT(*) FROM char_data;" || true
            done
          fi

          # Strict verification: if we expected N and don't have 1..N, fail fast.
          if [[ -n "$expected" ]]; then
            mapfile -t found_nums < <(
              ls -1 partial_outputs/achdb_${region}_b*.sqlite 2>/dev/null \
              | sed -n 's/.*_b\([0-9]\+\)\.sqlite/\1/p' | sort -n | uniq
            )
            missing=()
            for ((i=1; i<=expected; i++)); do
              if ! printf '%s\n' "${found_nums[@]}" | grep -qx "$i"; then
                missing+=("$i")
              fi
            done
            (( ${#missing[@]} == 0 )) || { echo "‚ùå Missing batches for $region/$sha: ${missing[*]}"; exit 1; }
          fi

      - name: Check disk usage
        run: df -h

      - name: Finalize region file
        env:
          REGION: ${{ needs.guard.outputs.region }}
          BLIZZARD_CLIENT_ID_EU_1:     ${{ secrets.BLIZZARD_CLIENT_ID_EU_1 }}
          BLIZZARD_CLIENT_SECRET_EU_1: ${{ secrets.BLIZZARD_CLIENT_SECRET_EU_1 }}
          BLIZZARD_CLIENT_ID_US_1:     ${{ secrets.BLIZZARD_CLIENT_ID_US_1 }}
          BLIZZARD_CLIENT_SECRET_US_1: ${{ secrets.BLIZZARD_CLIENT_SECRET_US_1 }}
          BLIZZARD_CLIENT_ID_TW_1:     ${{ secrets.BLIZZARD_CLIENT_ID_TW_1 }}
          BLIZZARD_CLIENT_SECRET_TW_1: ${{ secrets.BLIZZARD_CLIENT_SECRET_TW_1 }}
          BLIZZARD_CLIENT_ID_KR_1:     ${{ secrets.BLIZZARD_CLIENT_ID_KR_1 }}
          BLIZZARD_CLIENT_SECRET_KR_1: ${{ secrets.BLIZZARD_CLIENT_SECRET_KR_1 }}
          
          BLIZZARD_CLIENT_ID_EU_2:     ${{ secrets.BLIZZARD_CLIENT_ID_EU_2 }}
          BLIZZARD_CLIENT_SECRET_EU_2: ${{ secrets.BLIZZARD_CLIENT_SECRET_EU_2 }}
          BLIZZARD_CLIENT_ID_US_2:     ${{ secrets.BLIZZARD_CLIENT_ID_US_2 }}
          BLIZZARD_CLIENT_SECRET_US_2: ${{ secrets.BLIZZARD_CLIENT_SECRET_US_2 }}
          BLIZZARD_CLIENT_ID_TW_2:     ${{ secrets.BLIZZARD_CLIENT_ID_TW_2 }}
          BLIZZARD_CLIENT_SECRET_TW_2: ${{ secrets.BLIZZARD_CLIENT_SECRET_TW_2 }}
          BLIZZARD_CLIENT_ID_KR_2:     ${{ secrets.BLIZZARD_CLIENT_ID_KR_2 }}
          BLIZZARD_CLIENT_SECRET_KR_2: ${{ secrets.BLIZZARD_CLIENT_SECRET_KR_2 }}
          
          BLIZZARD_CLIENT_ID_EU_3:     ${{ secrets.BLIZZARD_CLIENT_ID_EU_3 }}
          BLIZZARD_CLIENT_SECRET_EU_3: ${{ secrets.BLIZZARD_CLIENT_SECRET_EU_3 }}
          BLIZZARD_CLIENT_ID_US_3:     ${{ secrets.BLIZZARD_CLIENT_ID_US_3 }}
          BLIZZARD_CLIENT_SECRET_US_3: ${{ secrets.BLIZZARD_CLIENT_SECRET_US_3 }}
          BLIZZARD_CLIENT_ID_TW_3:     ${{ secrets.BLIZZARD_CLIENT_ID_TW_3 }}
          BLIZZARD_CLIENT_SECRET_TW_3: ${{ secrets.BLIZZARD_CLIENT_SECRET_TW_3 }}
          BLIZZARD_CLIENT_ID_KR_3:     ${{ secrets.BLIZZARD_CLIENT_ID_KR_3 }}
          BLIZZARD_CLIENT_SECRET_KR_3: ${{ secrets.BLIZZARD_CLIENT_SECRET_KR_3 }}
          
          BLIZZARD_CLIENT_ID_EU_4:     ${{ secrets.BLIZZARD_CLIENT_ID_EU_4 }}
          BLIZZARD_CLIENT_SECRET_EU_4: ${{ secrets.BLIZZARD_CLIENT_SECRET_EU_4 }}
          BLIZZARD_CLIENT_ID_US_4:     ${{ secrets.BLIZZARD_CLIENT_ID_US_4 }}
          BLIZZARD_CLIENT_SECRET_US_4: ${{ secrets.BLIZZARD_CLIENT_SECRET_US_4 }}
          BLIZZARD_CLIENT_ID_TW_4:     ${{ secrets.BLIZZARD_CLIENT_ID_TW_4 }}
          BLIZZARD_CLIENT_SECRET_TW_4: ${{ secrets.BLIZZARD_CLIENT_SECRET_TW_4 }}
          BLIZZARD_CLIENT_ID_KR_4:     ${{ secrets.BLIZZARD_CLIENT_ID_KR_4 }}
          BLIZZARD_CLIENT_SECRET_KR_4: ${{ secrets.BLIZZARD_CLIENT_SECRET_KR_4 }}
          
          BLIZZARD_CLIENT_ID_EU_5:     ${{ secrets.BLIZZARD_CLIENT_ID_EU_5 }}
          BLIZZARD_CLIENT_SECRET_EU_5: ${{ secrets.BLIZZARD_CLIENT_SECRET_EU_5 }}
          BLIZZARD_CLIENT_ID_US_5:     ${{ secrets.BLIZZARD_CLIENT_ID_US_5 }}
          BLIZZARD_CLIENT_SECRET_US_5: ${{ secrets.BLIZZARD_CLIENT_SECRET_US_5 }}
          BLIZZARD_CLIENT_ID_TW_5:     ${{ secrets.BLIZZARD_CLIENT_ID_TW_5 }}
          BLIZZARD_CLIENT_SECRET_TW_5: ${{ secrets.BLIZZARD_CLIENT_SECRET_TW_5 }}
          BLIZZARD_CLIENT_ID_KR_5:     ${{ secrets.BLIZZARD_CLIENT_ID_KR_5 }}
          BLIZZARD_CLIENT_SECRET_KR_5: ${{ secrets.BLIZZARD_CLIENT_SECRET_KR_5 }}
          
          BLIZZARD_CLIENT_ID_EU_429:     ${{ secrets.BLIZZARD_CLIENT_ID_EU_429 }}
          BLIZZARD_CLIENT_SECRET_EU_429: ${{ secrets.BLIZZARD_CLIENT_SECRET_EU_429 }}
          BLIZZARD_CLIENT_ID_US_429:     ${{ secrets.BLIZZARD_CLIENT_ID_US_429 }}
          BLIZZARD_CLIENT_SECRET_US_429: ${{ secrets.BLIZZARD_CLIENT_SECRET_US_429 }}
          BLIZZARD_CLIENT_ID_TW_429:     ${{ secrets.BLIZZARD_CLIENT_ID_TW_429 }}
          BLIZZARD_CLIENT_SECRET_TW_429: ${{ secrets.BLIZZARD_CLIENT_SECRET_TW_429 }}
          BLIZZARD_CLIENT_ID_KR_429:     ${{ secrets.BLIZZARD_CLIENT_ID_KR_429 }}
          BLIZZARD_CLIENT_SECRET_KR_429: ${{ secrets.BLIZZARD_CLIENT_SECRET_KR_429 }}
          # finalize doesn‚Äôt actually use these, but the script reads them at import time
          BATCH_SIZE: "1"
          BATCH_ID: "0"
          TOTAL_BATCHES: "1"
          OFFSET: "0"
          LIMIT: "1"
        run: |
          set -euo pipefail
          echo "Merging batches and writing final region_${REGION}.lua‚Ä¶"
          python sync_pvp.py --mode finalize --region "$REGION"

      - name: Split oversized region Lua (if >‚ÄÜ49‚ÄØMB)
        id: split
        run: |
          REGION="${{ needs.guard.outputs.region }}"
          MAIN="region_${REGION}.lua"
          if [ -f "$MAIN" ]; then
            SIZE=$(stat -c%s "$MAIN")
            # 49 MiB = 49 * 1024 * 1024 = 51380224 bytes
            if [ "$SIZE" -gt 51380224 ]; then
              echo "üîé Splitting $MAIN ($SIZE bytes) into <49 MB parts..."
              split --bytes=49M --numeric-suffixes=1 --suffix-length=2 \
                    "$MAIN" "region_${REGION}-part-"
              rm "$MAIN"
              i=1
              for chunk in region_${REGION}-part-*; do
                mv "$chunk" "region_${REGION}-${i}.lua"
                echo " ‚úÖ Created region_${REGION}-${i}.lua ($(stat -c%s "region_${REGION}-${i}.lua") bytes)"
                i=$((i+1))
              done
            fi
          fi
   
      - name: Commit region Lua chunks (bypassing LFS)
        run: |
          REGION="${{ needs.guard.outputs.region }}"
          git config user.name "GitHub Action"
          git config user.email "action@github.com"
          # Override LFS filters so actual Lua content is committed, not pointer
          git -c filter.lfs.clean=cat \
              -c filter.lfs.smudge=cat \
              -c filter.lfs.process= \
              -c filter.lfs.required=false \
            add region_${REGION}*.lua
          git commit -m "Finalize PvP sync: region_${REGION} *.lua chunks" || true

      - name: Check if all 4 regions are finalized (main branch only)
        if: ${{ github.ref_name == 'main' }}
        run: |
          set -euo pipefail
          BRANCH="${{ github.event.workflow_run.head_branch || inputs.branch }}"
          REGION="${{ needs.guard.outputs.region }}"
          sha="${{ github.event.workflow_run.head_sha || inputs.sha }}"

          TRACKDIR=".github/workflows/finalize-tracker/main/$sha"
          mkdir -p "$TRACKDIR"
          echo "$REGION" > "$TRACKDIR/$REGION.done"

          count=$(ls "$TRACKDIR"/*.done 2>/dev/null | wc -l)
          echo "Found $count of 4 regions done so far for sha=$sha"

          if (( count < 4 )); then
            echo "üü° $REGION done, but waiting for all 4 regions on main branch ‚Üí skipping commit/tag"
            exit 0
          fi

          echo "‚úÖ All 4 regions finalized for sha=$sha ‚Äî continuing to commit + tag"

          # Cleanup everything except README.txt
          find "$TRACKDIR" -type f ! -name 'README.txt' -delete

      - name: Push finalized commit
        run: |
          set -euo pipefail
          BRANCH="${{ github.event.workflow_run.head_branch || inputs.branch }}"
          tries=0; max=6
          while :; do
            if git push origin "HEAD:${BRANCH}"; then
              echo "‚úÖ Pushed ${BRANCH}"
              break
            fi
            tries=$((tries+1))
            if (( tries >= max )); then
              echo "‚ùå Push failed after ${max} attempts"
              exit 1
            fi
            echo "‚ö†Ô∏è Push rejected; remote advanced‚Äîattempting to rebase on attempt ${tries}/${max}"
            git fetch origin "${BRANCH}"

            # üîß Safely rebase our local commit(s) (usually just region_*.lua)
            # onto the updated remote, stashing any unstaged changes.
            # Rebase while bypassing LFS filters
            git -c filter.lfs.clean=cat \
                -c filter.lfs.smudge=cat \
                -c filter.lfs.process= \
                -c filter.lfs.required=false \
              rebase --autostash origin/"${BRANCH}"

            # Git rebase --autostash handles unstaged files automatically.
            # If rebase fails due to conflict, stop early‚Äîmanual intervention may be needed.
            sleep $((2 * tries))
          done

      - name: Tag this commit (vA.BB [+ -beta] + date)
        run: |
          set -euo pipefail
          BRANCH="${{ github.event.workflow_run.head_branch || inputs.branch }}"

          # Use London time for date suffix
          TZ="Europe/London" ; export TZ
          DATE="$(date +%F)"  # YYYY-MM-DD

          # Make sure we see *all* tags
          git fetch --tags --force --prune

          if [[ "$BRANCH" == "dev" ]]; then
            # dev: only look at tags ending in -beta
            TAGS=$(git tag -l 'v*-beta')
          else
            # main: only look at tags NOT ending in -beta
            TAGS=$(git tag -l 'v*' | grep -Ev -- '-beta$' || true)
          fi

          # Extract vA.BB from matching tags
          BASES=$(sed -E 's/^(v[0-9]+\.[0-9]+).*/\1/' <<< "$TAGS" | sort -u -V)
          last_base=$(tail -n1 <<< "$BASES")

          if [[ -z "${last_base:-}" ]]; then
            major=1
            minor=0
          else
            major="$(sed -E 's/^v([0-9]+)\..*/\1/' <<< "$last_base")"
            minor="$(sed -E 's/^v[0-9]+\.([0-9]+).*/\1/' <<< "$last_base")"
          fi

          next_minor=$((10#$minor + 1))
          width="${#minor}"
          minor_fmt=$(printf "%0${width}d" "${next_minor}")
          base="v${major}.${minor_fmt}"

          suffix=""
          if [[ "$BRANCH" == "dev" ]]; then
            suffix="-beta"
          fi
          tag="${base}-${DATE}${suffix}"

          # Idempotency check: skip if this tag already exists
          if git rev-parse -q --verify "refs/tags/${tag}" >/dev/null; then
            echo "‚ÑπÔ∏è Tag ${tag} already exists; nothing to do."
            exit 0
          fi

          git tag -a "${tag}" -m "Automated tag for ${BRANCH} ${tag}"
          git push origin "refs/tags/${tag}"

      - name: Clean up temp DB outputs
        run: |
          rm -rf _dl partial_outputs || true
